# digest-lm

Digest code from GitHub repo, and LLM acts as a server.

### TODO

- [x] pull code from GitHub CLI
- [x] pipe code into Llama Preview
- [x] pipe user input into Llama Preview
- [ ] add this to a FastAPI app (maybe Golang for fun?)