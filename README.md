# digest-lm

Digest code from GitHub repo, and LLM acts as a server.

### TODO

- [ ] pull code from GitHub CLI
- [ ] pipe code into Llama Preview
- [ ] pipe user input into Llama Preview
- [ ] add this to a FastAPI app (maybe Golang for fun?)